AWS Interview Quiz
1. What is AWS? AWS stands for Amazon Web Service that uses distributed IT infrastructure to provide different IT resources services such as an infrastructure as a service, platform as a service, and software as a service.
2. What are the AWS components?
Simple storage service (S3)
Elastic Cloud Computing (EC2)
Elastic Block Storage (EBS)
CloudWatch
Route 53
3. What are the key-pair? Key-pair is public key cryptography for EC2 which is used to encrypt and decrypt the login information. the public key is used to encrypt the information while at the receiver's side, a private key is used to decrypt the information. The combination of a public key and the private key is known as key-pairs. Key-pairs allows you to access the instances securely.
4. What are the region and availability Zones and Edge locations? Regions: A region is a geographical area which consists of 2 or more availability zones. A region is a collection of data centers which are completely isolated from other regions. Availability zones: An Availability zone is a data center that can be somewhere in the country or city. Data center can have multiple servers, switches, firewalls, load balancing. The things through which you can interact with the cloud reside inside the Data center. Edge Location: Edge locations are the endpoints in aws used for caching content.
5. What is Elastic IP Address ? EIP (Elastic IP address) is a service provided by an EC2 instance. It is basically a static IP address attached to an EC2 instance. This address is associated with your AWS account not with an EC2 instance. You can also disassociate your EIP address from your EC2 instance and map it to another EC2 instance in your AWS account. Elastic IP address or static address is used which does not change.
6. How many Elastic IP you can create ? 5 elastic IP addresses that you can create per AWS account per region.
7. What are the two types access that you can provide when your create user ? Console-Access If the user wants to use the Console Access, a user needs to create a password to login in an AWS account. Programmatic-Access If you use the Programmatic access, an IAM user need to make an API calls. An API call can be made by using the AWS CLI. To use the AWS CLI, you need to create an access key ID and secret access key.
8. What is subnet ? Subnet is used to larger area network can be divided into small unit. 9. How many subnet you can assign per vpc ? You can have 200 subnets per VPC. 10. What AWS service that exist redundant cache data and images ? AWS Edge locations are services that redundantly cache data and images. 11. What are AWS services globally available ? IAM, S3, Route 53, CloudFront 12. What is Well-Architecture framework? a. Operational Excellence b. Security c. Reliability d. Performance Efficiency e. Cost Optimization f. Sustainability
IAM (Identity Access Management): 1. What is IAM ? IAM is Identity Access Management is securely controlling access to aws resources. It centrally manages users and permission, security credentials such as access key, secure key. 2. What does different entity provide by IAM? IAM users→ It is single entity that create to interact with AWS resource with some specific condition. IAM user groups→ it is collection of users. You can specify certain group that same for those users. IAM Policy→ It is permission to user for interact with aws service with conditions. IAM Role→ It is assigned to AWS resource to communicate each and other. To attach policy for communicate other resources. 3. What is AWS account root user? Root user is first creating of aws account. It grants access for all aws services in that account. After creating root user, it is recommended to create admin for manage service and everyday tasks, instead of root user. 4. What is AWS policy? Policies are object that associate with user, group, role to define permissions. Policies are store in JSON format.
5. What are the some best practise to manage AWS resources? Do not use root user→ Your root account has access to all your AWS resources and services. So best practice do not share to use. Use group→ Instead of giving aws service to induvial user, create group and assign to access and add user to that group. MFA→ MFA is addition layer security of basic user-id and password based on authentication. 6. What are the types of policies to support AWS? Identity-Based policy→ This policy bind with identities like user, group, role Resource-Based policy→ This policy predefined build with resources like S3 bucket. Permission Boundaries → Set maximum permission for IAM entity Organization’s SCP → Managing permission for all account in your organization. ACL and session policies → 7. In the IAM service, we can monitor user activity? Yes, you can monitor the actives of IAM users. If any violation, you can remove access for the IAM user. 8. How authentication controlled in IAM? You can manage users and can control access key, password, MFA. 9. What is federated user access management? A user who is allowed to access AWS resources from third-party vendors – such as Google, corporate credentials. 10. What are the top 5 credentials in AWS IAM? User-id and Password E-mail address and Password Access Keyes Key pair Multi-factor authentication 11. What are temporary security credentials? These are short-lived security credentials. These you can create from AWSSTS service (AWS security Token Service). 12. What are elements of IAM policy structure ? Effect — Decides whether the resource is allowed or denied (Allow/Deny) Action — A set of service-specific parameters Resource — Resource names Condition (Optional) — Grant conditions
CloudWatch: 1. What is CloudWatch? Amazon CloudWatch monitors your Amazon Web Services (AWS) resources and the applications you run on AWS in real time and You can use CloudWatch to collect and track metrics, for your applications. Integrate with EC2, ELB,SNS,Lambda,EBS 2. What is CloudWatch alarms? The new CloudWatch Alarms feature helps in monitoring CloudWatch metrics and receive notifications when threshold is met. That state of, Ok→ Metrix range is stable what you define Alarm→ When it reaches a certain threshold Insufficient data→ when the data required to make the decision is missing or incomplete. 3. Different of CloudWatch and CloudTrail? CloudWatch→ It monitor and collect Metrix of your aws resources. CloudTrail→ Collect all logs of your aws environment. (Insufficient activity) 4. What is CloudWatch service Lenses ? Amazon CloudWatch Service Lens is a new feature that lets you visualize and analyze the health, performance, and availability of your applications in one place. Amazon CloudWatch Service Lens is accessible in all public AWS Regions that offer AWS-X-Ray. 5. What is CloudWatch Metrics stream? CloudWatch Metric Streams is a feature that allows you to stream CloudWatch metrics to a destination of your choice indefinitely with minimal setup and configuration. It is a fully managed solution that eliminates the need for you to write code or maintain infrastructure. Users can configure a metric stream to destinations such as Amazon Simple Storage Service with a few clicks (S3). To maintain your operational dashboards up to date, users could also send the metrics to a number of third-party service providers. 6. What is CloudWatch synthetics? To monitor your endpoints and APIs, you can use Amazon CloudWatch Synthetics to create canaries, which are configurable scripts that run on a schedule. Canaries take the same routes and perform the same actions as customers, allowing you to continuously validate your customer experience even if there is no customer traffic on your applications. You can detect problems before your customers do by using canaries. Synthetic Monitoring is an effective way of testing a website or web service by simulating visitor requests to test for availability, performance, and functionality.
7. How can an application send custom Metrics to CloudWatch? An application can send custom metrics to CloudWatch by using the CloudWatch API. This allows the application to push custom metrics to CloudWatch, which can then be used to monitor the application. 8. Is it possible to disable CloudWatch? Yes, it is possible to disable CloudWatch. You can do this by going into the AWS console and selecting the CloudWatch service. From there, you can click on the “Actions” drop-down menu and select “Disable”. 9. How do integrate CloudWatch with EC2? You can integrate CloudWatch with EC2 instances by installing the CloudWatch agent on the instances. The CloudWatch agent allows you to collect metrics and log files from your EC2 instances and send them to CloudWatch. 10. . How billing calculate when using CloudWatch ? CloudWatch charges for the number of alarms that you have created, as well as the number of metric filters, the number of logs that you have created, and the number of metric alarms that you have created. 11. What feature do CloudWatch provide other monitoring tools ? CloudWatch provides a number of features that other monitoring tools don’t, including the ability to monitor AWS resources in real-time, set alarms to notify you of changes or issues, and automatically take action in response to changes or issues that are detected. Additionally, CloudWatch can be used to monitor non-AWS resources, such as on-premises servers. 12. What is log group and log stream ? Log group→ Log groups are used to group together similar logs, og groups can contain multiple log streams, but each log stream can only belong to one log group. Log stream→ log streams are used to monitor individual logs. 13. What is retention period in CloudWatch ? Retention period is the amount of time that CloudWatch will keep your data. The effect that it has on your data is that it will be deleted after the retention period expires. 14. How can i delete all log group in CloudWatch ? You can delete all log files from a particular group by using the AWS CloudWatch console. From the CloudWatch console, select the log group that you want to delete, then select the Actions drop-down menu. From the Actions menu, select Delete Log Group. 15. What is maximum number of alarms that can be each action? The maximum number of alarms that can be associated with each action is 100. You can display dashboard at a time is 100.
EC2 (Elastic Cloud Computing): 1. What is EC2? Amazon Elastic Compute Cloud (Amazon EC2) is a web service that provides scalable computing capacity in cloud. EC2 is no need to upfront cost for hardware equipment’s so you can easily deploy and faster your software. 2. What are the pricing models for EC2? On-Demand→ It model pay only for what you have used. It allows you to pay a fixed rate by the hour or even by the second with no long-term commitments or upfront payments. Reserved-Instance→ You can making reservation or contract with amazon. Making contract means it will give some discount for upfront cost. Spot Instance→ It request unused EC2 instance, which is low cost. Mostly used for testing purpose. Dedicated Host→ It is a physical EC2 server which is dedicated for your use. It reduces the overall costs by providing you a VPC that comprise of a dedicated hardware. 3. Different between terminate and stopping instance? Stopping→ you can stop an EC2 instance and stopping an instance means shutting down the instance. Its corresponding EBS volume is still attached to an EC2 instance, so you can restart the instance as well. Terminate→ You can also terminate the EC2 instance and terminating an instance means you are removing the instance from your AWS account. When you terminate an instance, then its corresponding EBS is also removed. Due to this reason, you cannot restart the EC2 instance. 4. What are the types of EC2? General Purpose→ General purpose instances provide a balance of compute, memory, and networking resources, and can be used for a wide range of workloads. Compute Optimize→ Compute optimize instance benefits for High processer-based application like, Gaming server, web application Memory Optimize→ Memory optimized instances to deliver fast performance for workloads that process large data sets in memory. Accelerator Computing→ Accelerated computing instances use hardware accelerators, or graphical proccing to perform functions such high graphical based applications. Storage Optimize→ Storage optimized instances are for workloads that require high, sequential read and write access to very large data sets on local storage. 5. What is spot instance? AWS Spot Instances let you make use of unused EC2 capacity on the AWS cloud. You can get Spot Instances at up to 90% off On-Demand prices. Spot Instances can be used for a testing purpose.
6. What is reserved instance? Reserved instance making contract or reserve with amazon. Contract means it will give some discount for upfront cost. Standard Rs, Convertible Rs, Schedule Rs 7. What are the benefits of EC2? Reliability→ 99.9% of availability and fast service. Security→ Amazon implement amazon vpc for stable network and security Flexibility→ You can increase and decrease your CPU, memory, storage-based workloads Cost saving→ Most important for reducing to manage hardware devices. 8. Explain basic structure of EC2? Instances- Instances are servers hosted in the AWS cloud using the EC2 services. AMI – AMI provides you the templates with an operating system and application pre-configured to reduce the chances of errors. EBS- A block-level storage device that you can attach to a single EC2 instance, EBS volume is a durable way to increase the disk space. Security Group- A security group provides a way to block the traffic of a particular machine from other network-connected computers for the security of the EC2 instance. IAM- Identity and Access Management, or IAM role, is used for managing access of AWS. VPC- AWS’ Virtual Private Cloud (VPC) allows you to set up a virtual network that AWS resources can then join. Load Balancers- Load Balancing distributes the incoming application or network traffic across multiple targets, such as Amazon EC2 instances, containers, and IP addresses, in multiple Availability Zones. Cloud Watch- The Amazon CloudWatch tool monitors all of your AWS resources and apps, collecting data and tracking variables in real time. 9. List various connections issue while connecting EC2? Server refusing Key Connection timeout unprotected Private Key Host Key missing User Key unrecognised 10. What is AMI in EC2? AMI stands for Amazon Machine Image that template of Instance in EC2. With one template you can create multiple EC2 instance. Mostly for Backup of EC2 instance with defined packages. 11. What is security group in EC2? Security group is acting firewall is controlling incoming and outgoing traffic for your instance. 12. What are the best practise in EC2? Security and network, Backup and recovery, Storage and resource management
13. What happened when EC2 is reboot? A reboot is like restarting a computer. The hard disk isn‘t affected. You don‘t get the image‘s original state back, but the hard disk’s contents revert to the original. 14. What does understand inbound and outbound security group? Outbound rules are the rules that are applied to allow traffic to leave a particular security group, while inbound rules are the rules that are applied to allow traffic to enter a particular security group. Inbound rules are generally more restrictive than outbound rules, since it is generally more important to control what is coming into a system than what is leaving it. 15. What is the best way to assign multiple IP’s through security group ? You can use Amazon’s EC2 security groups to allow multiple IP addresses to access a single instance. To do this, you will need to create a security group and add each IP address that you want to allow access to the group. You can then assign the security group to your instance. 16. Any limitation for creating security group per Account or region specify ? The maximum number of security groups that can be created per region is 100, and the maximum number of security groups that can be created per account is 500. 17. What is maximum packets allowed while creating new rule in security group ? The maximum size of a packet allowed while creating a new rule in a security group is 576 bytes. VPC ( Virtual Private Cloud ): 1. What is VPC ? VPC is virtual private cloud that form network layer in your cloud environment to run your aws resources. It completely provide in vpc environment such as Collection of IP’s, subnets, Routing, IGW. 2. What is VPC peering ? A VPC peering connection is a networking connection that allows you to connect one VPC with another VPC through a direct network route using private IP addresses. By using VPC peering connection, instances in different VPC can communicate with each other as if they were in the same network. 3. What is NAT gateway ? NAT stands for Network Address Translation. It is an aws service that enables to connect an EC2 instance in private subnet to the internet or other AWS services. 4. How can you control security in VPC ? Security group→ It act firewall to control incoming and outgoing traffics. NACL→ It controlling inbound and outbound traffics in subnet level.
5. Can you establish peering connection to different regions ? No, it's not possible to establish a peering connection to a VPC in a different region. It's only possible to establish a peering connection to a VPC in the same region. 6. How can you control security in VPC ? Subnet→ It divided large network to small network. Internet Gateway→ It connect your vpc to public network NAT gateway→ It used to access internet your EC2 with private network. Hardware VPN→ Connect between VPC to on-premises network Peering connection→ Enable connection between VPC within same region. VPC endpoint→ Enable to access S3 without Nat, IGW, and allow to access using endpoint polices 7. What is internet gateway in VPC ? Gateways establish coherent connections between your Amazon VPC network and the internet. 8. What is default vpc and advantages ? It’s a logically isolated virtual network that gets created automatically in AWS cloud for an account when the user makes use of Amazon EC2 resources for the first time. 9. What is private, public, elastic IP ? Private→ It is not accessible over internet which is only accessible internal network. A private IP address remains associated with the network interface will get released only when the instance is terminated Public→ Public IP is accessible for internet which is to access your instance through public network EIP→ Elastic IP is static IP address that is associate with EC2. When your restart or stop is doesn’t change it and easily associate disassociate EIP from EC2. 10. Is there any limit to number of vpc, subnet, NAT,GW,VPN can i create ? 5 VPC per region and 5 IGW per region Per vpc 200 subnets are allowed and 5 EIP are allowed per region 50 VPN connection per region 11. What is CIDR routing? CIDR is classless inter-domain routing is set of internet protocol standard that used to allocate IP address for network and induvial devices. In VPC, CIDR block size can be from /16 to /28 in case of IPv4. When you’re creating a VPC, you actually have to specify a range of IP address in form of CIDR just like 10.0.0.0/16. This CIDR is the primary CIDR block of your VPC.
12. What is stateful and stateless filtering? A stateful filtering checks the origin of the request and triggers automatic replay to the originating computer. stateless filtering only examines the source and destination IPs ignoring whether it’s a new request or replay to a request. security groups carry out stateful filtering whereas network ACLs perform stateless filtering. Stateful → This means any changes applied to an incoming rule will be automatically applied to the outgoing rule. Stateful consider as traffic direction Stateless → This means any changes applied to an incoming rule will not be applied to the outgoing rule. 13. What are the function of VPC router? VPC router allows Amazon EC2 instances within subnets to interact with Amazon EC2 instances in other subnets within the same VPC. Virtual private gateways, subnets and Internet gateways, etc. can also communicate with each other by means of a VPC router. 14. What is route table in vpc? A route table contains a set of rules, called routes, that decide where network traffic from your subnet or gateway is directed. 15. What is VPC endpoint, Gateway endpoint, Interface Endpoint? • VPC Endpoint→ A VPC endpoint enables connections between a virtual private cloud (VPC) and AWS Services, without requiring that you use an internet gateway, NAT device, VPN connection, or AWS Direct Connect connection. • Interface Endpoint→ An interface endpoint is powered by Private Link, and uses an elastic network interface (ENI) as an entry point for traffic destined to the service. Supported services are CloudWatch, SNS • Gateway Endpoint→ A Gateway Endpoint is a gateway in your route table that is a target to a specified route for the required AWS service. Supported for S3, DynamoDB 16. What is VPC flow logs? VPC Flow Log is a feature of aws that captures the information about the IP traffic going to or from the network interfaces in a VPC. Amazon Flow Log data can be either stored either by using the Amazon CloudWatch Logs or Amazon S3 bucket. 17. What is Traffic mirroring and Transits gateway? Copy network traffic from network interfaces and send it to security and monitoring appliances for deep packet inspection. You can connect your virtual private clouds (VPC) and on-premises networks using a transit gateway, which acts as a central hub, routing traffic between VPCs, VPN connections, and AWS Direct Connect connections.
18. What is VPN? VPN is virtual private network that used to safe and encrypted network that allows you to use network resources in a remote manner. S3 ( Simple Storage Service ): 1. What is S3 ? Simple storage service is storage in AWS. You can store any amount of data and retrieve anywhere on the web. You can store like pdf, html, documents. 2. What is bucket ? Bucket is a folder or container to store objects in S3. By default, you can create up 100 buckets. 3. What is object in S3 ? Object is any type of data or describe metadata. First you can create bucket then upload objects. 4. What is cross-region replication ? Cross region replication is service that enable to replicate data from one to other or same region. It provide asynchronies copies. 5. What is minimum and maximum size store in S3 ? The minimum size of an object that you can store in S3 is 0 bytes and the maximum size of an object that you can store in S3 is 5 TB. 6. What is different storage classes in S3? S3-Standard→ It is used for general purposes and offers high durability, availability, and performance object storage for frequently accessing our data. This class stored at least 3 AZ. S3-Infrequant Access→ For less frequently accessing our data with no longer storage time but for restoring cost is high. S3-One zone IA→ Who want to low-cost storage infrequent access but not needed multi availability zone. S3-Glacier→ Glacier is secure and low-cost data archiving and long-term backup. You can store data cost efficient month, years. 7. How can you secure S3 bucket ? ACL→ ACL is enable to managing access to bucket and object. It defines which AWS accounts or groups are granted access and the type of access. You can attach ACL each bucket and each object. Bucket Policies→ Bucket policies only applied in S3 bucket. It defines what access allow or denied. Bucket policies attach to bucket not object but applicable for each object within bucket.
8. How can you lock object in S3 ? Object lock is prevent from data loss or oversitting from unauthorized. To active object while creating bucket. It write once and read many (WORM) format. 9. What versioning in S3 and what is use? You can keep multi variant of an objects in s3 same bucket. 10. What is benefits of S3? Durability Flexibility Scalability Availability 11. What is key in S3? Key is unique identifier of object within bucket. Each bucket exactly one key. S3 is basic mapping between Bucket+key+versioning. 12. What is Bucket policy S3? Bucket policies allow you to grant access permissions to objects within your bucket by using AWS IAM policies. A bucket policy can only be associated with the bucket owner. An owner of a bucket can assign permissions to any object in the bucket that is attached to the bucket. 13. What is ACL S3? ACL is Access control list is used to manage access to s3 bucket and objects. Each bucket associate with ACL. It define grant access which AWS account or group along with type of access. 14. What is lifecycle of S3? when in an S3 bucket some data is stored for a longer time in standard storage even when not needed. The need to shift this old data to cheaper storage or delete it after a span of time gives rise to life cycle management. 15. What is CloudFront ? Amazon CloudFront speeds up distribution of your static and dynamic web content, such as .html, .css, .php, image, and media files. When users request your content, CloudFront delivers it through a worldwide network of edge locations that provide low latency and high performance. It is content delivery network.
EBS ( Elastic Block Storage ): 1. What is EBS volume ? EBS stands for elastic block storage that used to persistent your in Ec2instance. You can easily attach with only one instance and which is persistent your after reboot or terminate your instance. It offers high durability, availability, and low-latency performance required to run your workloads. 2. Any possible to EBS connect multiple instance ? No, it’s not possible to connect multiple instance to EBS volume, But you can connect multiple EBS to single instance. 3. What are the types of EBS volume ? General purpose SSD (gp2)→ SSD (Solid State Drive) is the volume with which EC2 chooses as the root volume of your instance by default Provisioned IOPS SSD (io1)→ This is the most expensive and fastest EBS volume that required High performance, Low latency They are benefits for large Relational or NoSQL databases. Throughput Optimize HDD (st1)→ These are low-cost magnetic storage volumes designed for frequently accessing workload that required higher throughput. Cold HDD (Sc1)→ These are older generation magnetic drives that are best suited for less frequent workloads. 4. What is maximum storage size of EBS? Maximum size of storage is 16TB. 5. How to allow an EBS volume available with no downtime and attach it to an EC2 instance when the EBS volume fails? You can add a load balancer and auto scaling, which will allow an EBS volume available with no downtime , and if the ec2 instance goes down due to autoscaling, a new instance will be created, and you can add commands to map to the EBS in the shell script. And when the EBS volume fails, we can take regular backups and replace the EBS with the most recent backup or snapshot if it fails. 6. What are the benefits of EBS? Reliable and secure storage- It automatically respond to its availability zone protecting from component failure. Secure- It allows us to specify access EBS volumes. High Performance- Delivers data results with consistent performance. Easy data backup-Taking point-in-time snapshot of EBS volume.
7. How can data transfer EBS to S3? Before doing this step, you can attach IAM role to EC2. To select Users and create an Administrator we can use this code: aws configure
Have you entered Access key and secret key→ aws s3 sync /ebs-directory/ s3://your-bucket
AMI ( Amazon Machine Image ): 18. What is AMI?
AMI stand Amazon Machine Image. It is template of EC2 image with cloud and with single image you can create multiple instance when you need same configuration of your instance. Full backup of storage.
19. What are the types of AMI provide by AWS ? Instance stored backend→ The root device for an instance launched from the AMI is an instance store volume created from a template stored in Amazon S3. EBS-Backend→ The root device for an instance launched from the AMI is an Amazon Elastic Block Store (Amazon EBS) volume created from an Amazon EBS snapshot.
20. Can we use Amazon Transfer acceleration and Snowball to transfer data across countries? Amazon Transfer Acceleration can accelerate Data Transfer by 300% with the help of amazon content delivery network and optimized networks. Whereas Snowball is not compatible to support Cross Region data transfer. 21. List virtualization types in AWS ? Hardware-Assisted-virtualization Para-virtualization ELB (Elastic Load Balancer): 1. What is Elastic Load balancer ? Elastic Load Balancing automatically distributes your incoming traffic across multiple targets, such as EC2 instances, containers, and IP addresses, in one or more Availability Zones. It monitors the health of its registered targets, and routes traffic only to the healthy targets. You can integrate with Autoscaling, EC2, CloudWatch, Route 53, CloudFront 2. What are the key features of Elastic Load balancer ? High Availability→ Distribute your load across multiple target Health Check→ if detect unhealthy target in ELB, stop sending traffic to redirect the healthy target until unhealthy back to recover. Security→ It associate with security group and VPC are provide additional layer of security 3. What is different between ELB and Autoscaling ? Load balancing evenly distributes load to application instances in all availability zones in a region while auto scaling makes sure instances scale up or down depending on the load. Ingress is used to map incoming traffic from the internet to the services running in the cluster.
4. How is Elastic Load balancer work ? A load balancer accepts incoming traffic from clients and routes requests to its registered targets (such as EC2 instances) in one or more Availability Zones. The load balancer also monitors the health of its registered targets and ensures that it routes traffic only to healthy targets. When the load balancer detects an unhealthy target, it stops routing traffic to that target. It then resumes routing traffic to that target when it detects that the target is healthy again. A listener is a process that checks for connection requests. It is configured with a protocol and port number for connections from clients to the load balancer. 5. What are the types of load balancer ?
• Application LB→ It allow to distribute incoming application traffic across multiple targets, such as EC2 instances, in multiple Availability Zones. • Network LB→ The load balancer distributes incoming TCP traffic across multiple targets, It works by combining two or more computers that are running applications into a single virtual cluster • Gateway LB→ GLB enable you to deploy, scale, and manage virtual appliances, such as firewalls, intrusion detection and prevention systems, and deep packet inspection systems. A Gateway Load Balancer operates at the third layer of the Open Systems Interconnection (OSI) model, the network layer. • Classic LB→ It provides basic load balancing across multiple Amazon EC2 instances and operates at both the request level and connection level.
6. List types of technique used by ELB ? Round Robin. Weighted Round Robin. Least Connection. Weighted Least Connection. Resource Based (Adaptive) Resource Based (SDN Adaptive) Fixed Weighting. Weighted Response Time. 7. What is mean target Group in ELB ? A target group tells a load balancer where to direct traffic to : EC2 instances, fixed IP addresses; or AWS Lambda functions, amongst others. 8. Explain NLB in AWS ? AWS Network Load Balancer (NLB) is an Amazon Web Services (AWS) tool that distributes end user traffic across multiple cloud resources to ensure low latency and high throughput for applications.When a target becomes slow or unavailable, the Network Load Balancer routes traffic to another target. 9. How do you choice which ELB for your application ? For http/https request you can used application LB For UDP/TCP request you can used network LB If your load balancer application build your EC2 classic network then you can use classic LB.
Autoscaling: 1. What is Auto scaling ? Autoscaling is automatically scale up and scale down your instance based on CPU utilizations. If you have running instance met threshold value then your instance automatically increase what you define in configuration and steady and predictable performance. 2. Benefits of Auto scaling ? Setup scale quickly Make smart scale decision Automatically maintain performance 3. What is use of lifecycle hook in Auto scaling ? Lifecycle hooks perform custom actions by pausing instances when Autoscaling group launches or terminates an instance. When instance is paused, an instance moves in a wait state. By default, an instance remains in a wait state for 1 hour. For example, when you launch a new instance, lifecycle hooks pauses an instance. When you pause an instance, you can install a software on it or make sure that an instance is completely ready to receive the traffic. 4. Different between horizontal scaling and vertical scaling ? Vertical scaling means scaling the compute power such as CPU, RAM to your existing machine while horizontal scaling means adding more machines to your server or database. Horizontal scaling means increasing the number of nodes, and distributing the tasks among different nodes. 5. How to add existing instance to autoscaling group ?
Open EC2 console
Select your instance under Instances
Choose Actions -> Instance Settings -> Attach to Auto Scaling Group
Select a new Auto Scaling group
Attach this group to the Instance
Edit the Instance if needed
Once done, you can successfully add the instance to a new Auto Scaling group
CloudFront: 1. What is CloudFront ? Amazon CloudFront speeds up distribution of your static and dynamic web content, such as .html, .css, .php, image, and media files. When users request your content, CloudFront delivers it through a worldwide network of edge locations that provide low latency and high performance. It is content delivery network. 2. What is Content Delivery Network(CDN) ? CDN is distributed network of that deliver web site and varies of materials to geographical locations. 3. How does work Content Delivery Network(CDN) ? The major task of CDN is creating cache content for speedup and low latency. 1. Users who visit your website or use your application expect to download files such as multimedia or HTML files. 2. As a result of DNS, requests are routed to the CloudFront POP (edge location) that best serves them. 3. CloudFront verifies its cache for the requested file in the POP. In this case, CloudFront sends the files to the user. 4. What happens in CDN if file is not present in cache to deliver user ? CloudFront verifies the request against your distribution's parameters and sends the files request to the appropriate origin server for the file type - for example, your Amazon S3 bucket for image files and your HTTP server for HTML files. The files are returned to the edge location by the origin servers. CloudFront starts forwarding files to the user as soon as the first byte arrives from the origin. CloudFront additionally saves the files in the edge location's cache for the next time they're requested. 5. What are the use case of CloudFront ? Livestreaming→ It get high volume request and process to live stream. Millions of people request at the same time maintaining a low-latency. Speedup → Speed up static content like html, png to view across global. 6. How to redirect custom domain to CloudFront ? We can use CloudFront Functions to redirect at the edge if we need to. There are two options if we wish to rewrite a URL: 2. Edit the Origin path field on your origin in the CloudFront console to /path if users want a request to CloudFront of example.com/foo to fetch your-origin.com/path/foo from your origin. 3. Can utilise CloudFront functions to rewrite the request.url as needed if the user wants a conditional URL rewrite.
7. What is CloudFront function ? Users can develop lightweight JavaScript functions for high-scale, latency-sensitive CDN customizations using CloudFront Functions in Amazon CloudFront. Such functions can handle CloudFront requests and responses, conduct basic authentication and authorization, and produce HTTP responses at the edge, among other things. The CloudFront Functions runtime environment is highly secure and has sub millisecond startup times. It scales instantly to accommodate millions of requests per second. Because CloudFront Functions is a built-in component of CloudFront, you can build, test, and deploy your code entirely within the platform. 8. What are the use case of CloudFront function ? Cache key normalisation - You could optimise your cache hit ratio by transforming HTTP request information (headers, query strings, cookies, and even the URL path) into an appropriate cache key. Header manipulation - In the request or response, you can insert, edit, or delete HTTP headers. Every request, for example, could include a True-Client-IP header. URL rewrites or redirects - You can rewrite all requests from one path to another or redirect users to other pages depending on information in the request. Request authorisation - You can analyse authorization headers or other request information to verify hashed authorization tokens, like JSON web tokens (JWT). 9. How can disable cache for CloudFront ? Minimum TTL - helps in specifying the minimum amount of time we want the objects to stay in CloudFront caches before CloudFront sends another request to our origin for determining if the object is updated. Maximum TTL - helps in specifying the maximum time we want the objects to stay in CloudFront caches before CloudFront sends another request to our origin for determining if the object is updated. Default TTL - helps in specifying the default time we want the objects to stay in CloudFront caches before CloudFront sends another request to our origin for determining if the object is updated.
Route53: 1. What is Route53? Amazon Route 53 is a highly available and scalable Domain Name System (DNS) web service. You can use Route 53 to perform three main functions in any combination: domain registration, DNS routing, and health checking. Route53 is bring your AWS intrastate service to public network with DNs name (Human readable format). 2. What are the functions of Route53? Register domain names→ Route53 register or convert your custom web application to domain name. Route internet traffic to aws services→ When a user opens a web browser and enters your domain name (example.com) or subdomain name (acme.example.com) in the address bar, Route 53 helps connect the browser with your website or web application. Check health of resource→ Route 53 sends automated requests over the internet to a resource, such as a web server, to verify that it's reachable, available, and functional. 3. What are the benefits of Route53? Amazon Route 53 is a service that connects a user's request to AWS infrastructure. It also has the advantage of helping in the setup of DNS health checks to route traffic to a healthy end-point. the health of the applications and their endpoints can be monitored independently. 4. What is CNAME ? CNAME is record used to alias name of other name. It stands for canonical name. For examplexample.com and www.example.com pointing to the same application and hosted by the same server. 5. What is NS record ? NS stands for 'nameserver,' and the nameserver record indicates which DNS server is authoritative for that domain. 6. What is NS record ? A DNS record is a database record used to map a URL to an IP address. DNS records are stored in DNS servers and work to help users connect their websites to the outside world. 7. Why would I use route53 instead of Google domain and GoDaddy ? Amazon Route 53 to Internet applications by translating human-readable names like www.example.com into the numeric IP addresses like 192.0.2.1 that computers use to connect to each other. Additionally, Amazon Route 53 integrates with other AWS Services, so you can use it to route end users to your Amazon EC2 instances, Amazon S3 buckets, and other AWS resources.
8. Is it possible to integrate route53 with other AWS services ? Yes, it is possible to integrate Amazon Route 53 with other AWS services like CloudFront and S3. You can do this by creating an Amazon Route 53 alias record that points to your CloudFront distribution or S3 bucket. 9. What are the different types of routing polices ? Simple routing policy→ Simple Routing Policy is a simple round-robin policy which is applied to a single resource doing the function for the domain. Weighted routing policy→ Weighted Routing Policy allows you to route the traffic to different resources in specified proportions. For example, 75% in one server, and 25% in another server. Low latency routing polices Failover routing policy Geolocation routing policy
Snapshot
1. What is EBS snapshot ?
It can back up the data on the EBS Volume. Snapshots are incremental backups.
First time only it will take complete backup after that taken new data only.
2. In EC2 instance have unencrypted volume how to create another ?
You can back up a storage using snapshot and attach to that EC2.
3. How can you automated EC2 backup using EBS ?
Backup using Data life cycle manager
4. How do you auto delete old snapshot ?
You can set the retention period while creating auto backup in Lifecycle.
Other Services: 1. What is Lambda ? It is serverless computing service, you can run code without provisioning or managing servers. You pay only for only when your application running. Just upload your code and Lambda takes care of everything required to run and scale your code with high availability or which is automatically trigger to other AWS service or direct to Web or Mobile App. 2. What are the language supported by Lambda ? Java, Python, js, C#, Ruby, Go, PowerShell 3. What Lambda function and trigger ? Lambda function is resources to upload your to run it. Trigger is configuration or another resource it easily integrate with other service like CloudWatch, SNS 4. What is layer in lambda ? Layer is contains package or module to reduce your deployment package so we can deploy faster. 5. What is RDS ? RDS stands for Relational database standard. It is distributed Relational Database Service (Amazon RDS) is a web service that makes it easily to set up, operate, and scale a relational database in the AWS Cloud. It provides cost-efficient, resizable capacity for manages common database administration tasks. 6. What is different types of RDS ? Amazon Aurora,Postgrade SQL,Mysql,MariaDB,Oracle 7. What is DB instance ? DB instance is isolated database environment in cloud. A dB instance can contains multiple user created database and you can easily through dB endpoint 8. Which database engine supported by RDS ? MySQL, Post grade, SQL server, MariaDB, Oracle 9. What is the maximum number of instance can user run in RDS ? By default 40 Amazon RDS can create it. 10. Is it possible to create multiple database in RDS ? MySQL→ No limit for database. You can create any number of databases Oracle→ 1 database for instance SQL server→ 30 databases per instance PostgreSQL→ No limit for creating databases 11. How to upgrade RDS instance ? Modify-dB-instance command can be used to upgrade your instance. 12. How can i enable automate backup in RDS ? Navigation pane -> Select databases -> Select DB instance that you want to modify. Select Backup retention period -> Provide a nonzero positive value, like 5 days. Choose Continue -> Choose Apply immediately.
13. What is Non-relational databases ? Non-relational database is NoSQL database that does not use the tabular schema of rows and columns. We have a Nonrelational Database. Inside the database, we have a collection. Inside a collection, we have got a document, and inside the document, we have key-value pairs 14. What is Data types of non-relational database? Key-value Document Memory Search 15. What is DynamoDB ? Amazon DynamoDB is a fully managed NoSQL database service that provides fast and predictable performance with seamless scalability. You can use Amazon DynamoDB to create a database table that can store and retrieve any amount of data. Data Types: Table→ table is collections of data. Items→ An item is a group of attributes that is uniquely identifiable among all of the other items. Attributes→ Attribute is fundamental data elements. 16. What is Amazon Aurora ? Amazon Aurora (Aurora) is a fully managed relational database engine that's compatible with MySQL and PostgreSQL. It provides cost-efficient, resizable capacity for an industry-standard relational database and manages common database administration tasks. 17. What is Aurora cluster ? An Amazon Aurora DB cluster consists of one or more DB instances and a cluster volume that manages the data for those DB instances. An Aurora cluster volume is a virtual database storage volume that spans multiple Availability Zones, with each Availability Zone having a copy of the DB cluster data. 18. Explain Primary DB and Aurora Replicas ? Primary DB→ Support read and write operation and perform all of the data modification to the cluster volume. Each Aurora DB cluster has one primary DB instance. Replicas→ When you create DB instance in aurora provisioned cluster that aurora automatically sets up replication from write DB instance to all other Db instance that DB instance as know Read-only replica. 19. What are the feature of Aurora ? Global database→ Global Database is single database that span multiple database in any region that is for read only low latency, Disaster recovery. Serverless→ Aurora serverless is on-demand, auto scaling feature for cos-efficient to running unpredictable workloads on Amazon aurora. It start automatically up,down,shuts down and scale capacity up or down, as based on workloads. 20. What is SNS ? Amazon Simple Notification Service (Amazon SNS) is a web service that enables applications, end-users, and devices to instantly send and receive notifications from the cloud.
21. What are the components of SNS ? Topics→ An Amazon SNS topic is a logical access point that acts as a communication channel for publisher and subscriber. Subscriber→ Subscriber is webserver, email, SQS, lambda function, receive the notification via protocol like http, email, SMS Publisher→ Communicate with subscriber by produce to sending message to topic. 22. What is SQS ? Amazon Simple Queue Service (Amazon SQS) is a fully managed message queuing service for storing message as they traveling between applications. 23. What is SES ? SES is email service that secure and cost-efficient to send and receive email using own email address or domain. 24. What is CloudFormation ? CloudFormation that uses template to automate and set up AWS resources. It build your application using AWS resource like EC2, ELB, Scaling without worrying about infrastructure. • Template→ Template is YAML or JSON format that uses to build your application using AWS resource. • Stack→ It collection of AWS resources to manage single unit. You can create, update, delete a collection of AWS resource by creating, update, delete stacks • Changeset→ When you make changes before you can generate changeset. • 25. What is CloudFormation ? Cloud computing means storing and accessing the data and program on remote server or console that are hosted on internet instead of local server and hard drive. 26. What are the cloud service Model ? • Infrastructure As service→ Hardware As service. The main advantage of using IaaS is that it helps users to avoid the purchasing and managing the physical servers. • Platform As service→ PaaS cloud computing platform is created for the programmer to develop, test, run, and manage the applications. • Software As service→ It is a software in which the applications are hosted by a cloud service provider. Users can access these applications with the help of internet connection and web browser Ports:
SSH
22
MongoDB
27017
SMTP
25
DynamoDB
8000
HTTP
80
Jenkins
8080
SMTPS
456
Grafana
3000
MSSQL
1433
Prometheus
9090
NFS
2049
Node Export
9100
MYSQL/Aurora
3306
RDP
3389
Post grade
5432
Terraform Interview Questions
1. What is Terraform?
Terraform is an open-source infrastructure as code software tool that enables you to safely and predictably create, change, and improve infrastructure.
2. What is IAC?
IAC stands for Infrastructure As code is managing and provision our infrastructure through code instead of manual process.
3. What are the features in Terraform?
Infrastructure As code → Build our infrastructure through code
Execution strategies → We can review our infrastructure before execute using plan strategies
Graph of Resource → we can view our infrastructure in graph view it is used give more about information.
Automation changes → Easily changes or modifying our infrastructure with no human InterVision.
4. What is the main reason for choosing to terraform in DevOps?
It provides amazing support to almost all the popular cloud providers like AWS, Azure, GCP, Digital Ocean, etc.
We can easily manage our infrastructure instead of manual process.
It is write Hashi Corp language so we can easily understand. The infrastructure as code is the foundation for DevOps practices such as continuous integration, version control, continuous deployment, and code review.
5. What understand by Terraform init?
The terraform init command initializes a working directory which is containing Terraform configuration files, like our cloud provider plugin configurations and child module files.
6. What is Terraform Backend?
A backend defines where terraform stores its state data files. Terraform uses persisted state data to keep track of the resources it manages. Most non-trivial Terraform configurations either integrate with Terraform Cloud or use a backend to store state remotely.
7. what is .terraform directory?
A backend defines where terraform stores its state data files. Terraform uses persisted state data to keep track of the resources it manages. Most non-trivial Terraform configurations either integrate with Terraform Cloud or use a backend to store state remotely.
8. What is some major competitor in terraform?
Packer, Cloud foundry, Kubernetes, Ansible
9. What is Terraform cloud-agentic? Terraform is cloud-agostic and allows a single configuration to manage multiple providers and handle cross-cloud dependencies. It is also used to simplify management and orchestration, facilitates operators to build large-scale multi-cloud infrastructures.
10. what is Terraform provider?
A provider in Terraform is a plugin that enables interaction with an API. This includes Cloud providers and Software-as-a-service providers. The providers are specified in the Terraform configuration code.
11. What is working of terraform core?
Terraform Core uses remote procedure calls (RPC) to communicate with Terraform Plugins and offers multiple ways to discover and load plugins to use. Terraform Plugins expose an implementation for a specific service, such as AWS, or provisioner, such as bash.
12. What is provisioner in Terraform?
Terraform Provisioners are used for executing scripts or shell commands on a local or remote machine as part of resource creation/deletion.
File provisioner → The file provisioner copies files or directories from the machine running Terraform to the newly created resource. The file provisioner supports both ssh and winrm type connections.
Local exec provisioner → The local-exec provisioner works on the Terraform host – where Terraform configuration is applied/executed. It is used to execute any shell command. It is used to set or read environment variables, details about the resource, which is created, invoke any process or application
Remote exec provisioner → The remote exec provisioner invokes a script on a remote resource after it is created. This can be used to run a configuration management tool, bootstrap into a cluster, etc. To invoke a local process, see the local exec provisioner instead.
13. What is Terraform cloud?
Terraform Cloud is HashiCorp's managed service offering. It eliminates the need for unnecessary tooling and documentation for practitioners, teams, and organizations to use Terraform in production. Provision infrastructure in a remote environment that is optimized for the Terraform workflow.
14. What is Terraform CLI? The Terraform CLI stands for Terraform Command Line Interface. It is used to manage infrastructure and interact with Terraform state, configuration files, providers, etc.
15. What is Modules in Terraform?
A Terraform module is a set of Terraform configuration files in a single directory. Even a simple configuration consisting of a single directory with one or more .tf files is a module. When you run Terraform commands directly from such a directory, it is considered the root module.
16. What are the most used commands in Terraform? terraform init: The terraform init CLI command is used to initiate the cloud provider plugins. terraform destroy: The terraform destroy CLI command is used to destroy the previously-created infrastructure. terraform validate: The terraform validate CLI command is used to check whether the configuration is valid or not. terraform apply: The terraform apply CLI command is used to create or update the infrastructure. terraform plan: The terraform plan CLI command shows the changes needed by the current configuration. terraform refresh: The terraform refresh CLI command is used to refresh the state file. terraform graph: The terraform graph CLI command creates a DOT-formatted graph.
17. What is private module registry? A Private Module Registry Terraform Cloud feature allows us to share Terraform modules across our organization.
18. How can two people using the Terraform cloud can create two different sets of infrastructure using the same working directory? By using different workspaces. These users can start Terraform runs in two separate workspaces. Each workspace has a state file of its own, so as long as the resources do not overlap, both the users can successfully provision two different sets of infrastructure using the same code.
19. What happens when multiple engineers start deploying infrastructure using the same state file? Terraform has a very important feature called “state locking”. This feature ensures that no changes are made to the state file during a run and prevents the state file from getting corrupt. It is important to note that not all Terraform Backends support the state locking Feature. You should choose the right backend if this feature is a requirement.
20. What is null resource in Terraform? A terraform null resource is a configuration that runs like a standard terraform resource block but does not create any resources. This may sound like a strange and useless resource, but it can be useful in various situations to work around limitations in Terraform.
21. You have a Terraform configuration file with no resources. What happens when you run the ter-raform apply command? Terraform will destroy all the resources. Starting an empty run with terraform apply command is the same as starting the terraform destroy run.
22. What happens if a resource was created successfully in terraform but failed during provisioning? This is an unlikely scenario, but when this happens, the resource is marked as tainted and can be recreated by restarting the terraform run.
23. Which value of the TF_LOG variable provides the MOST verbose logging? TRACE is the most verbose and the default value of the TF_LOG variable.
24. Which command can be used to switch between workspaces when using Terraform Cloud? The terraform workspace select <workspace-name> command is used to choose a different workspace.
25. What is terraform import? Terraform import is to invoke to IAC code which is already running or manually provisioned in the infrastructure. CMD: Terraform import <resource filename> resource ID
26. What is terraform Data source? Terraform data source is dynamically fetch data from API or other terraform backend, which means include Machine image ID fetch from cloud provider. Commands:
Command
Description
Terraform version
Shows the current version of terraform
Terraform fmt
To align the correct format using HCL language Standard
Terraform init
To prepare working directory and initialize plugins and modules
Terraform get
Download and install modules needed for the configurations.
Terraform validate
To validate your configuration file whether is getting any error or not
Terraform plan
To preview your infrastructure before executing to Realtime
Terraform apply
Create or update infrastructure depending on configuration files
Terraform destroy
To delete your infrastructure manged by terraform
Terraform taint
To mark a resource not fully functional. It will be deleted and re-created.
Terraform untaint
Remove from taint which is already taint
Terraform show
Show the state file in human-readable format
Terraform state show <resource Name>
Show the specific resource in the state file
Terraform import
Import infrastructure to terraform which is already running in real time.
Terraform providers
Display provider information
Terraform workspace
Run same configuration to different environment
Terraform output
List all output currently hold in state file
Terraform login
Login to terraform cloud using APT token
Terraform graph
You can view your infrastructure in graph view.
Docker Commands:
Command
Description
Docker pull
To download a docker image
Docker images
List all images which is downloaded in system
Docker run
To create a docker container from image
Docker ps -a
List all running containers
Docker exec
To login to docker container
Docker rm
To remove container with docker id
Docker image
To remove docker image with image id
Docker restart
To restart docker container with container id
Docker stop
To stop container with container id
Docker start
To start container with container ID
Docker kill
To stop the docker container immediately
Docker commit
To save new image with container ID in local system
Docker login
To login docker hub
Docker push
Upload a image to docker hub
Docker network ls
To list all docker networks
Docker prune
To remove all unused image or network container
Docker info
Information about docker
Docker cp <Cont-ID>:<local-path>
To copy file from docker to local system
Docker history <img-id>
Show the history of docker images
Docker logs <cont-id>
To show container logs
Docker search <img-nam>
To search image on docker hub
Docker volume ls
List docker volumes
Docker swarm init
To create a docker swarm
Docker node ls
To list docker nodes
Docker swarm join
To join the node to swarm manager
Docker service create
To create a new service
Docker service ls
Lis available service
Docker service inspect
Display the details information about specific service
Docker service rm
Remove docker service
Docker service scale
Scale our service
Docker service ps
Display the running task and part specific service
Docker service update
Update specific service
Docker-compose up
To get generate a containers
Docker-compose down
To stop all services in containers
Docker-compose up -d
To run the docker-compose file Kubernetes Commands:
Command
Description
Kubectl get node
To view connected work node
Kubectl describe <N/P>
Describe the node or resource
Kubectl get pods
To list available pods
Kubectl get pods -o wide
List pods in wide range
Kubeadm reset
Leave from kube cluster
Kubectl get deploy
To list available deployment
Kubectl get svc
To list available services
Kubectl get namespace
To list available namespace
Kubectl get -n <namespace>
To list specific namespace
Kubectl get secret -o wide
To list available secret object
Kubectl api-version
To print the supported version of API
Kubectl apply -f <filename>
To configure a resource by file
Kubectl attach <pod> -c <container>
To attach things to the running container
Kubectl config
To modify the kubeconfig file
Kubectl config delete-cluster <cluster-name>
To delete specific cluster from kubeconfig
Kubectl get-cluster <cluster-name>
To display the information about specific cluster
Kubectl config se-cluster
Set cluster entry in Kubernetes
Kubectl cp <s-f><d-f>
Copy files from containers
Kubectl delete <resource name>
To delete resource by filename
